{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1ce/TMvZbQluj5SleUOoB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uujx8BuWdKdI","executionInfo":{"status":"ok","timestamp":1727758954180,"user_tz":-330,"elapsed":11617,"user":{"displayName":"PRABU T (RA2111026050011)","userId":"05959560485014660632"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=1):\n","        super(UNet, self).__init__()\n","\n","        # Encoder\n","        self.encoder1 = self.conv_block(in_channels, 64)\n","        self.encoder2 = self.conv_block(64, 128)\n","        self.encoder3 = self.conv_block(128, 256)\n","        self.encoder4 = self.conv_block(256, 512)\n","\n","        # Bottleneck\n","        self.bottleneck = self.conv_block(512, 1024)\n","\n","        # Decoder\n","        self.decoder4 = self.upconv_block(1024, 512)\n","        self.decoder3 = self.upconv_block(512, 256)\n","        self.decoder2 = self.upconv_block(256, 128)\n","        self.decoder1 = self.upconv_block(128, 64)\n","\n","        # Final layer\n","        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n","\n","    def conv_block(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def upconv_block(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        # Encoder path\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(F.max_pool2d(enc1, kernel_size=2))\n","        enc3 = self.encoder3(F.max_pool2d(enc2, kernel_size=2))\n","        enc4 = self.encoder4(F.max_pool2d(enc3, kernel_size=2))\n","\n","        # Bottleneck\n","        bottleneck = self.bottleneck(F.max_pool2d(enc4, kernel_size=2))\n","\n","        # Decoder path\n","        dec4 = self.decoder4(bottleneck)\n","        dec4 = torch.cat((dec4, enc4), dim=1)  # Skip connection\n","        dec3 = self.decoder3(dec4)\n","        dec3 = torch.cat((dec3, enc3), dim=1)  # Skip connection\n","        dec2 = self.decoder2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)  # Skip connection\n","        dec1 = self.decoder1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)  # Skip connection\n","\n","        return self.final(dec1)\n"]},{"cell_type":"code","source":["import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","\n","# Assuming you have a Dataset class defined to load your MRI images and masks\n","class CustomDataset(Dataset):\n","    def __init__(self, image_paths, mask_paths, transform=None):\n","        self.image_paths = image_paths\n","        self.mask_paths = mask_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)  # Load image\n","        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)  # Load mask\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask\n","\n","# Define hyperparameters\n","num_epochs = 20\n","batch_size = 8\n","learning_rate = 0.001\n","\n","# Create DataLoader\n","train_dataset = CustomDataset(train_image_paths, train_mask_paths, transform=get_augmentation_pipeline())\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Instantiate model, loss function, and optimizer\n","model = UNet(in_channels=1, out_channels=1)  # Adjust in_channels and out_channels as needed\n","criterion = nn.BCEWithLogitsLoss()  # Use BCE Loss for binary segmentation\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()  # Set model to training mode\n","    running_loss = 0.0\n","\n","    for images, masks in train_loader:\n","        optimizer.zero_grad()  # Reset gradients\n","        outputs = model(images.unsqueeze(1).float())  # Add channel dimension\n","        loss = criterion(outputs, masks.unsqueeze(1).float())  # Add channel dimension\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","        running_loss += loss.item()\n","\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"],"metadata":{"id":"LybKo68KdT_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, val_loader):\n","    model.eval()  # Set model to evaluation mode\n","    dice_scores = []\n","\n","    with torch.no_grad():  # No need to compute gradients\n","        for images, masks in val_loader:\n","            outputs = model(images.unsqueeze(1).float())\n","            preds = torch.sigmoid(outputs) > 0.5  # Apply sigmoid and threshold\n","            dice_score = compute_dice_coefficient(preds, masks.unsqueeze(1).float())\n","            dice_scores.append(dice_score)\n","\n","    mean_dice_score = np.mean(dice_scores)\n","    print(f'Mean DICE Score: {mean_dice_score:.4f}')\n","\n","def compute_dice_coefficient(preds, targets):\n","    smooth = 1e-6  # To avoid division by zero\n","    preds_flat = preds.view(-1)\n","    targets_flat = targets.view(-1)\n","    intersection = (preds_flat * targets_flat).sum()\n","    return (2. * intersection + smooth) / (preds_flat.sum() + targets_flat.sum() + smooth)\n"],"metadata":{"id":"LbojmRy8dU0e","executionInfo":{"status":"aborted","timestamp":1727758962861,"user_tz":-330,"elapsed":4,"user":{"displayName":"PRABU T (RA2111026050011)","userId":"05959560485014660632"}}},"execution_count":null,"outputs":[]}]}